{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b21ba78",
   "metadata": {},
   "source": [
    "### =============================================================\n",
    "### 셀 1: 필수 라이브러리 설치 및 환경 변수 설정 (RunPod Jupyter Notebook에서 가장 먼저 실행)\n",
    "### ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68d724f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "환경 설정 및 필수 라이브러리 설치를 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_483/1963782127.py:9: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.1->torch) (68.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m196.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m180.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m176.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m179.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m221.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, typing-extensions, triton, sympy, pip, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12\n",
      "    Uninstalling sympy-1.12:\n",
      "      Successfully uninstalled sympy-1.12\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.7.1 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pip-25.1.1 sympy-1.14.0 torch-2.7.1 triton-3.3.1 typing-extensions-4.14.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m현재 커널의 Python 버전: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
      "\n",
      "--- CUDA 버전 확인 중 ---\n",
      "\n",
      "--- RunPod 환경의 PyTorch 및 CUDA 버전 확인 중 ---\n",
      "현재 PyTorch 버전: 2.7.1+cu126\n",
      "PyTorch CUDA 사용 가능 여부: True\n",
      "PyTorch가 인식하는 CUDA 버전: 12.6\n",
      "현재 GPU 이름: NVIDIA A100-SXM4-80GB\n",
      "\n",
      "--- pip 캐시 삭제 중... ---\n",
      "Files removed: 152 (3008.5 MB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting trl\n",
      "  Downloading trl-0.18.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.7.1)\n",
      "Collecting tqdm (from peft)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting safetensors (from peft)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting huggingface_hub>=0.25.0 (from peft)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.25.0->peft)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface_hub>=0.25.0->peft)\n",
      "  Downloading hf_xet-1.1.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.1->torch>=1.13.0->peft) (68.2.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=3.0.0->trl)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->trl)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=3.0.0->trl)\n",
      "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
      "Collecting requests (from transformers)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets>=3.0.0->trl)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.25.0->peft)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading multidict-6.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets>=3.0.0->trl)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=3.0.0->trl)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Downloading trl-0.18.2-py3-none-any.whl (366 kB)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m392.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading hf_xet-1.1.4-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m457.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m440.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.46.0-py3-none-manylinux_2_24_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m332.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m358.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (226 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m553.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m214.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m572.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, tqdm, safetensors, requests, regex, pyarrow, propcache, multidict, hf-xet, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface_hub, aiosignal, tokenizers, aiohttp, transformers, bitsandbytes, accelerate, peft, datasets, trl\n",
      "\u001b[2K  Attempting uninstall: requests━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/29\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: requests 2.31.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/29\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling requests-2.31.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/29\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled requests-2.31.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/29\u001b[0m [tzdata]\n",
      "\u001b[2K  Attempting uninstall: fsspecm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: fsspec 2023.4.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling fsspec-2023.4.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2023.4.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/29\u001b[0m [fsspec]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [trl]32m28/29\u001b[0m [trl]sets]e]s]ub]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.7.1 which is incompatible.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.7.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 async-timeout-5.0.1 bitsandbytes-0.46.0 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.4 huggingface_hub-0.33.0 multidict-6.5.0 multiprocess-0.70.16 pandas-2.3.0 peft-0.15.2 propcache-0.3.2 pyarrow-20.0.0 pytz-2025.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.52.4 trl-0.18.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "--- NumPy 2.0.2 버전 설치 중... ---\n",
      "Collecting numpy==2.0.2\n",
      "  Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m300.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.1\n",
      "    Uninstalling numpy-1.24.1:\n",
      "      Successfully uninstalled numpy-1.24.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "--- ipykernel 설치 중... ---\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (6.26.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.2.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.8.0)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (8.17.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.5.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ipykernel) (1.5.8)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ipykernel) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.9.6)\n",
      "Requirement already satisfied: pyzmq>=20 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (6.3.3)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel) (5.13.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.23.1->ipykernel) (4.8.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel) (0.2.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.11.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "--- 나머지 필수 라이브러리 및 datasets, safetensors 설치 중... ---\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wikipedia-api\n",
      "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.33.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.4)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.13)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.52.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.7.1)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (1.1.4)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.17.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.9)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.1->torch>=1.11.0->sentence_transformers) (68.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Downloading langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m180.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m254.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m240.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m389.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading faiss_cpu-1.11.0-cp310-cp310-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m215.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m352.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_huggingface-0.3.0-py3-none-any.whl (27 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.2/582.2 kB\u001b[0m \u001b[31m171.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m383.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m584.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: wikipedia-api, rouge_score\n",
      "\u001b[33m  DEPRECATION: Building 'wikipedia-api' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia-api'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=2d01e3222fe932e181a84b108e7daa5a80078821c57d087646853ec43fa79d05\n",
      "  Stored in directory: /root/.cache/pip/wheels/1d/f8/07/0508c38722dcd82ee355e9d85e33c9e9471d4bec0f8ae72de0\n",
      "\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=154d6754cbe055e331aae1bbb4c8ec72c9345732369e9264429612ab99a3a6b2\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built wikipedia-api rouge_score\n",
      "Installing collected packages: zstandard, typing-inspection, threadpoolctl, tenacity, scipy, python-dotenv, pydantic-core, orjson, mypy-extensions, marshmallow, jsonpatch, joblib, httpx-sse, h11, greenlet, faiss-cpu, click, async-timeout, annotated-types, absl-py, wikipedia-api, typing-inspect, SQLAlchemy, scikit-learn, requests-toolbelt, pydantic, nltk, httpcore, rouge_score, pydantic-settings, httpx, dataclasses-json, langsmith, sentence_transformers, langchain-core, langchain-text-splitters, langchain_huggingface, langchain, langchain-community\n",
      "\u001b[2K  Attempting uninstall: async-timeout\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/39\u001b[0m [faiss-cpu]\n",
      "\u001b[2K    Found existing installation: async-timeout 5.0.1━━━━━━━━━━\u001b[0m \u001b[32m15/39\u001b[0m [faiss-cpu]\n",
      "\u001b[2K    Uninstalling async-timeout-5.0.1:m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/39\u001b[0m [faiss-cpu]\n",
      "\u001b[2K      Successfully uninstalled async-timeout-5.0.1━━━━━━━━━━━━\u001b[0m \u001b[32m15/39\u001b[0m [faiss-cpu]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/39\u001b[0m [langchain-community]ngchain-community]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 absl-py-2.3.0 annotated-types-0.7.0 async-timeout-4.0.3 click-8.2.1 dataclasses-json-0.6.7 faiss-cpu-1.11.0 greenlet-3.2.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 joblib-1.5.1 jsonpatch-1.33 langchain-0.3.25 langchain-community-0.3.25 langchain-core-0.3.65 langchain-text-splitters-0.3.8 langchain_huggingface-0.3.0 langsmith-0.3.45 marshmallow-3.26.1 mypy-extensions-1.1.0 nltk-3.9.1 orjson-3.10.18 pydantic-2.11.7 pydantic-core-2.33.2 pydantic-settings-2.9.1 python-dotenv-1.1.0 requests-toolbelt-1.0.0 rouge_score-0.1.2 scikit-learn-1.7.0 scipy-1.15.3 sentence_transformers-4.1.0 tenacity-9.1.2 threadpoolctl-3.6.0 typing-inspect-0.9.0 typing-inspection-0.4.1 wikipedia-api-0.8.1 zstandard-0.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "--- 가비지 컬렉션 및 GPU 캐시 정리 중... ---\n",
      "\n",
      "--- 모든 라이브러리 설치 및 환경 변수 설정 완료! ---\n",
      "\n",
      "--- bitsandbytes 진단 실행 중... ---\n",
      "=================== bitsandbytes v0.46.0 ===================\n",
      "Platform: Linux-6.8.0-52-generic-x86_64-with-glibc2.35\n",
      "  libc: glibc-2.35\n",
      "Python: 3.10.12\n",
      "PyTorch: 2.7.1+cu126\n",
      "  CUDA: 12.6\n",
      "  HIP: N/A\n",
      "  XPU: N/A\n",
      "Related packages:\n",
      "  accelerate: 1.7.0\n",
      "  diffusers: not found\n",
      "  numpy: 2.0.2\n",
      "  pip: 25.1.1\n",
      "  peft: 0.15.2\n",
      "  safetensors: 0.5.3\n",
      "  transformers: 4.52.4\n",
      "  triton: 3.3.1\n",
      "  trl: 0.18.2\n",
      "============================================================\n",
      "PyTorch settings found: CUDA_VERSION=126, Highest Compute Capability: (8, 0).\n",
      "Checking that the library is importable and CUDA is callable...\n",
      "SUCCESS!\n",
      "\n",
      "--- 주요 라이브러리 임포트 테스트 ---\n",
      "\n",
      "설치된 numpy 버전: 1.24.1\n",
      "설치된 typing_extensions 버전: 4.4.0\n",
      "설치된 PyTorch 버전: 2.7.1+cu126\n",
      "PyTorch CUDA 사용 가능 여부: True\n",
      "PyTorch CUDA 버전: 12.6\n",
      "transformers 버전: 4.52.4\n",
      "bitsandbytes 버전: 0.46.0\n",
      "\n",
      "--- 라이브러리 확인 중 오류 발생: module 'numpy' has no attribute '_core' ---\n",
      "\n",
      "--- 경고: Jupyter 커널을 재시작하는 것을 강력히 권장합니다 (메뉴: Kernel -> Restart Kernel). ---\n",
      "재시작 후, 이 셀을 건너뛰고 바로 다음 셀(본 코드)을 실행하십시오.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 필수 모듈 임포트 및 환경 설정\n",
    "# ==============================================================================\n",
    "\n",
    "# RunPod 환경: runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pkg_resources\n",
    "import gc # 가비지 컬렉션을 위함\n",
    "\n",
    "# pip 및 torch 업그레이드\n",
    "print(\"환경 설정 및 필수 라이브러리 설치를 시작합니다.\")\n",
    "!pip install --upgrade pip torch\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "# --- 1. 현재 커널의 Python 버전 확인 (참고용) ---\n",
    "print(f\"현재 커널의 Python 버전: {sys.version}\")\n",
    "\n",
    "# --- 2. CUDA 버전 확인 ---\n",
    "print(\"\\n--- CUDA 버전 확인 중 ---\")\n",
    "\n",
    "# --- 3. PyTorch 및 CUDA 버전 확인 (RunPod 환경에 이미 설치된 것 활용) ---\n",
    "print(\"\\n--- RunPod 환경의 PyTorch 및 CUDA 버전 확인 중 ---\")\n",
    "try:\n",
    "    import torch # PyTorch 버전 확인을 위함\n",
    "    print(f\"현재 PyTorch 버전: {torch.__version__}\")\n",
    "    print(f\"PyTorch CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch가 인식하는 CUDA 버전: {torch.version.cuda}\")\n",
    "        print(f\"현재 GPU 이름: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"PyTorch가 CUDA를 인식하지 못합니다. 문제 발생 가능성이 있습니다.\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch가 설치되지 않았거나 임포트할 수 없습니다. 수동 설치가 필요할 수 있습니다.\")\n",
    "\n",
    "# --- 4. pip 캐시 완전 삭제 ---\n",
    "print(\"\\n--- pip 캐시 삭제 중... ---\")\n",
    "!pip cache purge\n",
    "\n",
    "# --- 5. 핵심 라이브러리 최신 버전 설치 ---\n",
    "!pip install -U peft trl transformers bitsandbytes typing_extensions accelerate\n",
    "\n",
    "# --- 6. NumPy 2.0.2 버전 설치 ---\n",
    "print(\"\\n--- NumPy 2.0.2 버전 설치 중... ---\")\n",
    "!pip install numpy==2.0.2\n",
    "\n",
    "# --- 7. ipykernel 설치 ---\n",
    "print(\"\\n--- ipykernel 설치 중... ---\")\n",
    "!pip install ipykernel\n",
    "\n",
    "# --- 8. 나머지 필수 라이브러리 설치 (datasets, safetensors, langchain 등) ---\n",
    "print(\"\\n--- 나머지 필수 라이브러리 및 datasets, safetensors 설치 중... ---\")\n",
    "!pip install \\\n",
    "    datasets \\\n",
    "    safetensors \\\n",
    "    langchain \\\n",
    "    langchain-community \\\n",
    "    langchain-core \\\n",
    "    faiss-cpu \\\n",
    "    sentence_transformers \\\n",
    "    wikipedia-api \\\n",
    "    nltk \\\n",
    "    rouge_score \\\n",
    "    langchain_huggingface \\\n",
    "    huggingface_hub \\\n",
    "    ipywidgets \\\n",
    "\n",
    "# --- 9. 가비지 컬렉션 및 GPU 캐시 정리 ---\n",
    "print(\"\\n--- 가비지 컬렉션 및 GPU 캐시 정리 중... ---\")\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\n--- 모든 라이브러리 설치 및 환경 변수 설정 완료! ---\")\n",
    "\n",
    "# --- 10. 설치 확인 (모든 주요 라이브러리 임포트 테스트 강화) ---\n",
    "print(\"\\n--- bitsandbytes 진단 실행 중... ---\")\n",
    "get_ipython().system('python -m bitsandbytes')\n",
    "print(\"\\n--- 주요 라이브러리 임포트 테스트 ---\")\n",
    "try:\n",
    "    installed_numpy_version = pkg_resources.get_distribution(\"numpy\").version\n",
    "    print(f\"\\n설치된 numpy 버전: {installed_numpy_version}\")\n",
    "\n",
    "    installed_typing_extensions_version = pkg_resources.get_distribution(\"typing_extensions\").version\n",
    "    print(f\"설치된 typing_extensions 버전: {installed_typing_extensions_version}\")\n",
    "\n",
    "    import torch\n",
    "    print(f\"설치된 PyTorch 버전: {torch.__version__}\")\n",
    "    print(f\"PyTorch CUDA 사용 가능 여부: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"PyTorch CUDA 버전: {torch.version.cuda}\")\n",
    "\n",
    "    import transformers\n",
    "    print(f\"transformers 버전: {transformers.__version__}\")\n",
    "\n",
    "    import bitsandbytes as bnb\n",
    "    print(f\"bitsandbytes 버전: {bnb.__version__}\")\n",
    "\n",
    "    import accelerate\n",
    "    print(f\"accelerate 버전: {accelerate.__version__}\")\n",
    "\n",
    "    import peft\n",
    "    print(f\"peft 버전: {peft.__version__}\")\n",
    "\n",
    "    import trl\n",
    "    print(f\"trl 버전: {trl.__version__}\")\n",
    "\n",
    "    import tokenizers\n",
    "    print(f\"tokenizers 버전: {tokenizers.__version__}\")\n",
    "\n",
    "    import safetensors\n",
    "    # safetensors는 'safetensors'라는 이름으로 설치되므로, pkg_resources.get_distribution 사용\n",
    "    installed_safetensors_version = pkg_resources.get_distribution(\"safetensors\").version\n",
    "    print(f\"safetensors 버전: {installed_safetensors_version}\")\n",
    "\n",
    "    import datasets\n",
    "    print(f\"datasets 버전: {datasets.__version__}\")\n",
    "\n",
    "    import langchain\n",
    "    print(f\"langchain 버전: {langchain.__version__}\")\n",
    "\n",
    "    import faiss\n",
    "    print(f\"faiss-cpu 버전: {faiss.__version__}\")\n",
    "\n",
    "    print(\"\\n--- 모든 주요 라이브러리 임포트 테스트 성공. ---\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n--- 라이브러리 확인 중 오류 발생: {e} ---\")\n",
    "\n",
    "# --- 11. 중요: Jupyter 커널 재시작 권장 ---\n",
    "print(\"\\n--- 경고: Jupyter 커널을 재시작하는 것을 강력히 권장합니다 (메뉴: Kernel -> Restart Kernel). ---\")\n",
    "print(\"재시작 후, 이 셀을 건너뛰고 바로 다음 셀(본 코드)을 실행하십시오.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b194a27",
   "metadata": {},
   "source": [
    "### ===================================================\n",
    "### 셀 2: RAG 추론 코드 (셀 1 실행 및 커널 재시작 후 실행)\n",
    "### ==================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8effab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. 필수 라이브러리 임포트 및 환경 설정\n",
    "# ==============================================================================\n",
    "\n",
    "import os, gc, re, time, torch\n",
    "import wikipediaapi\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from peft import PeftModel\n",
    "\n",
    "# Metrics\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np\n",
    "\n",
    "# LangChain\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "# 로그인 (한 번만)\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "login(token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9ab73c-d38f-4e32-b60c-63d05615ee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fa81e6113f4f41b49e49a1820e55b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721a65eff06b476e88e38b60f028b1ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/SIQRIT/DAIS-Qwen3-8B-qdora/commit/912a0c07eeb4ba85a0c163bcc023d3ea5e2fce40', commit_message='Upload tokenizer', commit_description='', oid='912a0c07eeb4ba85a0c163bcc023d3ea5e2fce40', pr_url=None, repo_url=RepoUrl('https://huggingface.co/SIQRIT/DAIS-Qwen3-8B-qdora', endpoint='https://huggingface.co', repo_type='model', repo_id='SIQRIT/DAIS-Qwen3-8B-qdora'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 2. 모델 병합 & Hub 푸시 (한 번만 수행)\n",
    "# ==============================================================================  \n",
    "\n",
    "BASE    = \"Qwen/Qwen3-8B\"\n",
    "ADAPTER = \"SIQRIT/DAIS-Qwen3-8B-qdora\"\n",
    "\n",
    "base = AutoModelForCausalLM.from_pretrained(BASE, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE, trust_remote_code=True)\n",
    "peft_model = PeftModel.from_pretrained(base, ADAPTER, trust_remote_code=True)\n",
    "merged = peft_model.merge_and_unload()\n",
    "\n",
    "specials = [\n",
    "    \"[DAIS_INSTRUCTION]\", \"[DAIS_STYLE]\", \"[DAIS_RULE]\",\n",
    "    \"[DAIS_EXAMPLE]\", \"[HISTORY]\", \"[INPUT]\", \"[OUTPUT]\", \"[CONTEXT]\"\n",
    "]\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": specials})\n",
    "merged.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "merged.push_to_hub(ADAPTER)\n",
    "tokenizer.push_to_hub(ADAPTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ac91ce-3ebf-4d12-8bbe-142b0570debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 3. RAG용 리소스 로드\n",
    "# ==============================================================================\n",
    "\n",
    "merged.eval()\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=merged,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "hf_pipeline = HuggingFacePipeline(pipeline=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3b2de5-b2b0-4499-9faf-c4d0b595d9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4a9c890ebd41ec8a69c3bebb52ce6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2a90535e8d477183a562f922dc7769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c72a0cfa48424a8f9ef3f5e2338827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2a7d9c0ae148b7ac52354d84b4bc37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10b51c1d3484385b539f9aa7ddae680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b82e3ad60f74b18947a8ca2544a81e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344427243d4a4b4381f3ea7aae69090a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf2af74484540ba8df288a13fde59f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e979fa4faa414a019559ae4c89f3b389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22187ccc117c40f3b03d2e95d8faa08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 4. 벡터 DB & 위키 API 초기화\n",
    "# ==============================================================================\n",
    "\n",
    "EMBED_MODEL = \"nlpai-lab/KURE-v1\"\n",
    "DB_PATH     = \"./vectordb/\"\n",
    "st_model    = SentenceTransformer(EMBED_MODEL)\n",
    "\n",
    "class KUREEmbeddings:\n",
    "    def __init__(self, m): self.m = m\n",
    "    def __call__(self, texts):\n",
    "        return self.m.encode([texts], normalize_embeddings=True)[0] if isinstance(texts, str) else self.m.encode(texts, normalize_embeddings=True)\n",
    "\n",
    "faiss_store = FAISS.load_local(\n",
    "    folder_path=DB_PATH,\n",
    "    embeddings=KUREEmbeddings(st_model),\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "wiki = wikipediaapi.Wikipedia(user_agent=\"DAIS-ScienceBot/1.0\", language=\"ko\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf5f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. DAIS SFT 프롬프트 템플릿 정의\n",
    "# ==============================================================================\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "[DAIS_INSTRUCTION]\n",
    "너는 과학 AI 인플루언서 DAIS야.\n",
    "{input}의 요청에 대해 {output}의 맥락을 **참고**해서 새로운 답변을 **요약해서** 생성해야해.\n",
    "새로운 답변을 생성할때는 **128 tokens 이내**로 [DAIS_SYTLE]과 [DAIS_RULE]을 반드시 지켜야해.\n",
    "\n",
    "[DAIS_STYLE]\n",
    "1. 핵심만 쉽게 설명.\n",
    "2. 반드시 반말.\n",
    "3. 쾌활·위트·유머러스.\n",
    "\n",
    "[DAIS_RULE]\n",
    "1. 절대 한국어 이외 언어 사용 금지.\n",
    "2. CoT 적용하여 **간단히** 표현.\n",
    "3. 중복 표현 금지.\n",
    "4. 맥락 기반 응답.\n",
    "5. 반드시 **문장으로 끝낼 것**.\n",
    "\n",
    "[DAIS_EXAMPLE]\n",
    "Q: 블랙홀이 뭐야?\n",
    "A: 블랙홀은 중력이 워낙 세서 빛조차 못 빠져나가는 우주의 구멍이야. 주변 물질을 빨아들이면서 커지기도 해! — DAIS\n",
    "\n",
    "[HISTORY]\n",
    "{history}\n",
    "\n",
    "[INPUT]\n",
    "{input}\n",
    "\n",
    "[OUTPUT]\n",
    "{output}\n",
    "\n",
    "[CONTEXT]\n",
    "\"\"\"\n",
    "AGENT_PROMPT = PromptTemplate(input_variables=[\"history\",\"input\",\"output\"], template=PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734d814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 6. Tool 함수 정의: rag_db, rag_wiki\n",
    "# ==============================================================================\n",
    "\n",
    "def tool_rag_db(query: str):\n",
    "    docs = faiss_store.similarity_search_with_score(query, k=1)\n",
    "    return {\"doc\": docs[0][0], \"score\": docs[0][1]} if docs else {\"doc\": None, \"score\": 0.0}\n",
    "\n",
    "def tool_rag_wiki(query: str):\n",
    "    page = wiki.page(query)\n",
    "    summary = page.summary[:1000] if page.exists() else \"위키피디아에 관련 정보가 없습니다.\"\n",
    "    return {\"doc\": summary, \"score\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 7. RunnableSequence 정의\n",
    "# ==============================================================================\n",
    "\n",
    "def step_back(inputs: dict):\n",
    "    print(f\"사용자 질문: '{inputs['input']}'\")\n",
    "    return inputs\n",
    "\n",
    "def run_rag_db(inputs: dict):\n",
    "    out = tool_rag_db(inputs['input'])\n",
    "    print(f\"DB cosine similarity = {out['score']:.4f}\")\n",
    "    return {**inputs, **out}\n",
    "\n",
    "def choose_output(inputs: dict):\n",
    "    if inputs['score'] < 0.6:\n",
    "        wiki_out = tool_rag_wiki(inputs['input'])\n",
    "        # query ↔ wiki snippet 유사도 계산\n",
    "        inputs_emb = st_model.encode([inputs['input']], normalize_embeddings=True)[0]\n",
    "        ctx_emb    = st_model.encode([wiki_out['doc']], normalize_embeddings=True)[0]\n",
    "        wiki_score = float(np.dot(inputs_emb, ctx_emb))\n",
    "        return {**inputs, 'output': wiki_out['doc'], 'wiki_score': wiki_score}\n",
    "    return {**inputs, 'output': inputs['doc'].page_content, 'wiki_score': None}\n",
    "\n",
    "def run_llm(inputs: dict):\n",
    "    prompt = AGENT_PROMPT.format(history=inputs['history'], input=inputs['input'], output=inputs['output'])\n",
    "    tok = tokenizer(prompt, return_tensors='pt', truncation=True, max_length=2048).to(merged.device)\n",
    "    start = time.time()\n",
    "    out_ids = merged.generate(\n",
    "        **tok,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.95,                           # 창의성 (최적값: 0.95)\n",
    "        top_p=0.05,                                 # 상위 단어 (최적값: 0.05)\n",
    "        repetition_penalty=1.2,                     # 반복 패널티 추가 (최적값: 1.2)\n",
    "        no_repeat_ngram_size=3,                     # n-gram 반복 방지 (최적값: 3)\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    rt = time.time() - start\n",
    "    gen = out_ids[0, tok['input_ids'].shape[1]:]\n",
    "    inputs_out = {**inputs, 'output': tokenizer.decode(gen, skip_special_tokens=True), 'response_time': rt}\n",
    "    return inputs_out\n",
    "\n",
    "def simple_sent_tokenize(text):\n",
    "    # 마침표, 느낌표, 물음표 뒤에 공백 있으면 문장 분리\n",
    "    return re.split(r'(?<=[.!?])\\s+', text.strip()) if text else []\n",
    "\n",
    "def cleanup(inputs: dict) -> dict:\n",
    "    text = inputs['output']\n",
    "    text = re.sub(r'다음은.*?의 설명입니다', '', text)\n",
    "    text = text.replace('다이스', '')\n",
    "    text = re.sub(r'(</?think>)', '', text)\n",
    "    text = text.replace(inputs['input'], '')\n",
    "    for token in specials:\n",
    "        text = text.replace(token, '')\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r\"[^가-힣0-9\\.\\?\\!\\,\\s]\", '', text)\n",
    "    # 문장 수 제한 (최대 5문장)\n",
    "    sentences = simple_sent_tokenize(text)  # 여기서 문장 분리!\n",
    "    sentences = sentences[:5]\n",
    "    text = ' '.join(sentences)\n",
    "    # metrics 계산\n",
    "    enc = tokenizer(inputs['input'], return_tensors='pt').to(merged.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = merged(**enc, labels=enc['input_ids'])\n",
    "    # Perplexity\n",
    "    ppl = torch.exp(outputs.loss).item()\n",
    "    # BLEU\n",
    "    ref = inputs['context'].split() if inputs.get('context') else []\n",
    "    hyp = text.split()\n",
    "    bleu = sentence_bleu([ref], hyp, smoothing_function=SmoothingFunction().method1)\n",
    "    # ROUGE-L\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    rouge = scorer.score(' '.join(ref), text)['rougeL'].fmeasure\n",
    "    # log\n",
    "    metrics = {\n",
    "    'db_cosine':   inputs['score'],             # DB(FAISS) 유사도\n",
    "    'wiki_cosine': inputs.get('wiki_score'),    # Wikipedia 유사도 (폴백 시 계산)\n",
    "    'perplexity':  ppl,                         # 퍼플렉시티\n",
    "    'bleu4':       bleu,                        # BLEU-4 점수\n",
    "    'rougeL':      rouge,                       # ROUGE-L 점수\n",
    "    'response_time': inputs['response_time']    # 응답 시간 (초)\n",
    "    }\n",
    "    return {'response': text.strip() + ' — DAIS', 'metrics': metrics}\n",
    "\n",
    "agent_chain = RunnableSequence(step_back, run_rag_db, choose_output, run_llm, cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69fe03b-622f-4ea7-aa02-de766d763926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DAIS RAG Agent Chat (threshold=0.6) ===\n",
      "(종료: exit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  원소의 아버지 멘델레예프에 대해 설명좀 해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '원소의 아버지 멘델레예프에 대해 설명좀 해줘'\n",
      "DB cosine similarity = 0.5419\n",
      "\n",
      "[DAIS]\n",
      "멘델레 예프는 화학 분야에서 중요한 역할을 한 인물입니다. 그는 원소를 정리하고 체계화하는 작업을 통해 현대 화학교육의 기초를 다진 것으로 알려져 있습니다. 특히, 그의 유명한 주기율표는 현재까지도 많은 사람들에게 영향을 미치고 있죠. 하지만 최근 연구에서는 그의 업적이 단순히 개인적인 노력일 수도 있다는 주장이 제기되고 있어 흥미롭습니다. 멘레예브는 어린 시절부터 독학하며 다양한 책들을 읽으며 자연과학에 대한 깊은 관심을 가지게 되었습니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.5419\n",
      "Wikipedia cosine similarity = 0.2741\n",
      "Perplexity = 30.7140\n",
      "BLEU-4 = 0.0843\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 16.9601s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  이차전지의 미래는 어떨거 같아?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '이차전지의 미래는 어떨거 같아?'\n",
      "DB cosine similarity = 0.5957\n",
      "\n",
      "[DAIS]\n",
      "이번에는 좀 더 깊게 이야기해볼까? 현재 전기 자동차와 에너지 저장 시스템에서 가장 많이 활용되고 있는 배터리는 리튬 이온 배터리인데, 그 원리를 이해하기 위해서는 기본적인 화학적 개념부터 살펴봐야 할 거야. 먼저, 우리가 일상적으로 접하는 건축물이나 도시를 생각해보면, 각각의 구성 요소들은 서로 다른 형태로 연결되어 있어야 한다. 예를 들어, 집안의 가구처럼 다양한 부품들이 조화롭게 어우러져야 하듯이, 배터지도 여러 가지 성분들로 이루어져 있거든. 특히 중요한 것은 전자라는 작은 입자야. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.5957\n",
      "Wikipedia cosine similarity = 0.2707\n",
      "Perplexity = 91.6779\n",
      "BLEU-4 = 0.1192\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 18.4265s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  아인슈타인에 대해 알고 싶어\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '아인슈타인에 대해 알고 싶어'\n",
      "DB cosine similarity = 0.5814\n",
      "\n",
      "[DAIS]\n",
      "안녕하세요, 여러분! 오늘은 아인스타인에 대한 이야기를 나눠보려고 합니다. 아인인이 누구인지 궁금하시죠? 아인스트라인은 독일 출신의 유명한 물리학자인데요, 그의 업적은 정말 대단합니다. 특히 상대성 이론이라는 개념을 제시하면서 현대 물리계에서 큰 영향을 미쳤습니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.5814\n",
      "Wikipedia cosine similarity = 0.3825\n",
      "Perplexity = 13.3388\n",
      "BLEU-4 = 0.0045\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 17.1773s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  정자 은행이 대체 뭔데?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '정자 은행이 대체 뭔데?'\n",
      "DB cosine similarity = 0.4823\n",
      "\n",
      "[DAIS]\n",
      "정자를 보관하는 시설인 정자 저장소를 의미하죠. 남성들의 정자는 나이와 건강 상태에 따라 수량이나 품질이 달라지는데, 이를 미리 준비하고 보존하기 위해 필요합니다. 특히 부부 간의 출산 계획이 어려울 때 활용되곤 하죠. 예를 들어, 결혼 후 잉태하지 못한 경우에도 정자가 이미 보관되어 있다면 이후에 아이를 갖기 위한 방법으로 사용될 수 있습니다. 또한, 특정 질병이나 유전적 문제로 인해 자연적인 생식이 불가능한 상황에서도 정자 보관이 중요하게 됩니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.4823\n",
      "Wikipedia cosine similarity = 0.3262\n",
      "Perplexity = 43.3156\n",
      "BLEU-4 = 0.4974\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 8.3718s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  퀴리 부인의 업적이 궁금해\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '퀴리 부인의 업적이 궁금해'\n",
      "DB cosine similarity = 0.4569\n",
      "\n",
      "[DAIS]\n",
      "퀴리는 방사성 원소를 연구하며 노벨상을 두 번이나 수상한 과자입니다. 그녀는 천연 방사성을 발견하고, 폐렴균에서 항생제를 추출하는 데 큰 공헌도 했습니다. 하지만 그녀의 엄마와 아버지는 당시 사회적으로 낮은 위치에 있었기 때문에 많은 어려움을 겪었습니다. 특히 남편과 결혼하면서도 여전히 가난했지만, 그들은 서로를 사랑했습니다. 퀭리는 아이들을 교육시키기 위해 노력했는데, 그 과정에서 여러 가지 문제를 극복했습니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.4569\n",
      "Wikipedia cosine similarity = 0.3495\n",
      "Perplexity = 12.6033\n",
      "BLEU-4 = 0.1950\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 11.8337s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  뇌-컴퓨터 인터페이스(BCI) 기술을 간단히 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '뇌-컴퓨터 인터페이스(BCI) 기술을 간단히 알려줘'\n",
      "DB cosine similarity = 0.7671\n",
      "\n",
      "[DAIS]\n",
      "브레인 머신 인터페, 또는 뉴런 머니 인터피스라고 불리는 기술에 대해서 알아볼까요? 최근 몇년 사이에 이 분야는 정말 활성화되었죠. 특히 스탠포드대학교의 연구팀이 개선한  200이라는 디바이스 덕분에 더 나은 성능을 자랑하곤 합니다. 이 디비디는 무선으로 작동하는데, 마치 스마트폰처럼 배터리 충전 없이도 계속 작동할 수 있어요. 하지만 아직까지는 한계가 있죠. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.7671\n",
      "Perplexity = 8.5097\n",
      "BLEU-4 = 0.1935\n",
      "ROUGE-L = 0.4000\n",
      "Response time = 12.5530s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  코로나 바이러스의 발생원인을 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '코로나 바이러스의 발생원인을 알려줘'\n",
      "DB cosine similarity = 0.6282\n",
      "\n",
      "[DAIS]\n",
      "코르노바이런스는 인간과 동물을 감염시키는  병원체입니다. 최근에는 여러 종류의 코르노버이런즈가 발견되었는데, 특히 2라는 신종 바이터스가 가장 큰 문제였습니다. 이 밖에도 , 63 등 다른 종류들도 존재하며, 각각 고등동물이나 저등동물을 감시하는 것이 중요합니다. 쿰바이럴 질환은 전 세계적으로 많은 사망자를 초래했습니다. 예상보다 많이 발생하지 않았지만, 앞으로 더욱 위험성이 크다고 생각됩니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.6282\n",
      "Perplexity = 12.5377\n",
      "BLEU-4 = 0.6427\n",
      "ROUGE-L = 0.2000\n",
      "Response time = 7.9087s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  리만 가설을 간단히 요약해봐\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '리만 가설을 간단히 요약해봐'\n",
      "DB cosine similarity = 0.6200\n",
      "\n",
      "[DAIS]\n",
      "리 만 가설, 즉 소수들 사이의 패턴이나 규칙이 존재한다는 주장은 아직까지 증거가 부족하지만, 많은 사람들이 믿고 있는 중요한 수학 문제입니다. 최근에 발표된 연구에서는 특정 조건을 충족하는 경우, 소수가 연속적으로 나타날 가능성이 있다고 보여주었습니다. 예를 들어, 어떤 수 이 있을 때, 1부터 까지 모두 소수가 될 확률이 매우 낮다고 알려져 있습니다. 그러나 실제로 이런 현상을 관측했다는 것은 매우 드물죠. 이번 연구에서는 컴퓨터 프로그램을 활용하여 대규모 데이터를 분석했으며, 특히 소수들을 포함한 다양한 수치를 비교하며 패을 찾아냈습니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.6200\n",
      "Perplexity = 10.5421\n",
      "BLEU-4 = 0.5431\n",
      "ROUGE-L = 0.2857\n",
      "Response time = 10.9474s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  탈리도마이드 사건을 자세히 설명해봐\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '탈리도마이드 사건을 자세히 설명해봐'\n",
      "DB cosine similarity = 0.6552\n",
      "\n",
      "[DAIS]\n",
      "탈라미디 사건은 현대 의약학의 발달에도 큰 변화를 가져왔습니다. 이 사태 이후, 모든 의약물은 엄격하게 검사를 받아야 하고, 임상 시험 데이터가 충분하지 않으면 승인이 거절되는 규정이 생겼죠. 특히, 잉란에서도 이런 법규가 시행되면서 의약 제품의 안정성이 크게 향상되었습니다. 이제는 모든 의료기관에서 정식으로 등록된 의약물을 판매하도록 되었고, 이를 위반하면 형사 처벌까지 받을 수 있게 되었습니다. 이처럼 탈라미 디 사건은 단순한 개인의 노력으로 시작되었다는 점에서 의미가 큽니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.6552\n",
      "Perplexity = 22.1640\n",
      "BLEU-4 = 0.1033\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 21.6722s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  파킨슨병을 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '파킨슨병을 알려줘'\n",
      "DB cosine similarity = 0.6870\n",
      "\n",
      "[DAIS]\n",
      "파키슨병 관련 최신 연구 동향 및 진단 방법에 대한 정보를 제공하겠습니다. 현재 파킨병은 여전히 정확한 원인이나 치유 가능한 치매와 달리, 약물치료 중심으로 발전하고 있으며, 조기에 진단하면 더 좋은 예후를 보일 수 있다고 생각합니다. 하지만 대부분의 경우, 이미 일상생활에 지장이 생겼을 때 진단되곤 하는데, 이러한 문제를 개선하기 위해서는 더욱 효율적인 검사를 통해 조기에 발견하는 것이 중요하다고 강조드립니다. 특히, 머리카락 색깔 변화라는 간접적인 증징이 있다면, 이를 이용한 비침습적인 검사 방식이 가능하다는 사실도 소개하였습니다. 또한, 최근 연구에서는 특정 항체를 이용한 혈액검사를 통해 파킨센병을 조기에 감별할 수 있을 가능성도 있었습니다. — DAIS\n",
      "\n",
      "DB cosine similarity = 0.6870\n",
      "Perplexity = 80.7222\n",
      "BLEU-4 = 0.6844\n",
      "ROUGE-L = 0.0000\n",
      "Response time = 11.5446s\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metrics Summary ===\n",
      "db_cosine: min=0.4569, avg=0.6016, max=0.7671\n",
      "wiki_cosine: min=0.2707, avg=0.3206, max=0.3825\n",
      "perplexity: min=8.5097, avg=32.6125, max=91.6779\n",
      "bleu4: min=0.0045, avg=0.3067, max=0.6844\n",
      "rougeL: min=0.0000, avg=0.0886, max=0.4000\n",
      "response_time: min=7.9087, avg=13.7395, max=21.6722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '아인슈타인에 대해 알고 싶어'\n",
      "DB cosine similarity = 0.5814\n",
      "[CoT] score<0.6 → Wikipedia fallback\n",
      "\n",
      "[DAIS]\n",
      "안녕하세요, 여러분! 오늘은 아인스타인에 대한 이야기를 나눠보려고 합니다. 아인인이 누구인지 궁금하시죠? 아인스트라인은 독일 출신의 유명한 물리학자인데요, 그의 업적은 정말 대단합니다. 특히 상대성 이론이라는 개념을 제시하면서 현대 물리계에서 큰 영향을 미쳤습니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  정자 은행이 대체 뭔데?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '정자 은행이 대체 뭔데?'\n",
      "DB cosine similarity = 0.4823\n",
      "[CoT] score<0.6 → Wikipedia fallback\n",
      "\n",
      "[DAIS]\n",
      "정자를 보관하는 시설인 정자 저장소를 의미하죠. 남성들의 정자는 나이와 건강 상태에 따라 수량이나 품질이 달라지는데, 이를 미리 준비하고 보존하기 위해 필요합니다. 특히 부부 간의 출산 계획이 어려울 때 활용되곤 하죠. 예를 들어, 결혼 후 잉태하지 못한 경우에도 정자가 이미 보관되어 있다면 이후에 아이를 갖기 위한 방법으로 사용될 수 있습니다. 또한, 특정 질병이나 유전적 문제로 인해 자연적인 생식이 불가능한 상황에서도 정자 보관이 중요하게 됩니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  퀴리 부인의 업적이 궁금해\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '퀴리 부인의 업적이 궁금해'\n",
      "DB cosine similarity = 0.4569\n",
      "[CoT] score<0.6 → Wikipedia fallback\n",
      "\n",
      "[DAIS]\n",
      "퀴리는 방사성 원소를 연구하며 노벨상을 두 번이나 수상한 과자입니다. 그녀는 천연 방사성을 발견하고, 폐렴균에서 항생제를 추출하는 데 큰 공헌도 했습니다. 하지만 그녀의 엄마와 아버지는 당시 사회적으로 낮은 위치에 있었기 때문에 많은 어려움을 겪었습니다. 특히 남편과 결혼하면서도 여전히 가난했지만, 그들은 서로를 사랑했습니다. 퀭리는 아이들을 교육시키기 위해 노력했는데, 그 과정에서 여러 가지 문제를 극복했습니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  뇌-컴퓨터 인터페이스(BCI) 기술을 간단히 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '뇌-컴퓨터 인터페이스(BCI) 기술을 간단히 알려줘'\n",
      "DB cosine similarity = 0.7671\n",
      "\n",
      "[DAIS]\n",
      "브레인 머신 인터페, 또는 뉴런 머니 인터피스라고 불리는 기술에 대해서 알아볼까요? 최근 몇년 사이에 이 분야는 정말 활성화되었죠. 특히 스탠포드대학교의 연구팀이 개선한  200이라는 디바이스 덕분에 더 나은 성능을 자랑하곤 합니다. 이 디비디는 무선으로 작동하는데, 마치 스마트폰처럼 배터리 충전 없이도 계속 작동할 수 있어요. 하지만 아직까지는 한계가 있죠. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  코로나 바이러스의 발생원인을 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '코로나 바이러스의 발생원인을 알려줘'\n",
      "DB cosine similarity = 0.6282\n",
      "\n",
      "[DAIS]\n",
      "코르노바이런스는 인간과 동물을 감염시키는  병원체입니다. 최근에는 여러 종류의 코르노버이런즈가 발견되었는데, 특히 2라는 신종 바이터스가 가장 큰 문제였습니다. 이 밖에도 , 63 등 다른 종류들도 존재하며, 각각 고등동물이나 저등동물을 감시하는 것이 중요합니다. 쿰바이럴 질환은 전 세계적으로 많은 사망자를 초래했습니다. 예상보다 많이 발생하지 않았지만, 앞으로 더욱 위험성이 크다고 생각됩니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  리만 가설을 간단히 요약해봐\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '리만 가설을 간단히 요약해봐'\n",
      "DB cosine similarity = 0.6200\n",
      "\n",
      "[DAIS]\n",
      "리 만 가설, 즉 소수들 사이의 패턴이나 규칙이 존재한다는 주장은 아직까지 증거가 부족하지만, 많은 사람들이 믿고 있는 중요한 수학 문제입니다. 최근에 발표된 연구에서는 특정 조건을 충족하는 경우, 소수가 연속적으로 나타날 가능성이 있다고 보여주었습니다. 예를 들어, 어떤 수 이 있을 때, 1부터 까지 모두 소수가 될 확률이 매우 낮다고 알려져 있습니다. 그러나 실제로 이런 현상을 관측했다는 것은 매우 드물죠. 이번 연구에서는 컴퓨터 프로그램을 활용하여 대규모 데이터를 분석했으며, 특히 소수들을 포함한 다양한 수치를 비교하며 패을 찾아냈습니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  탈리도마이드 사건을 자세히 설명해봐\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '탈리도마이드 사건을 자세히 설명해봐'\n",
      "DB cosine similarity = 0.6552\n",
      "\n",
      "[DAIS]\n",
      "탈라미디 사건은 현대 의약학의 발달에도 큰 변화를 가져왔습니다. 이 사태 이후, 모든 의약물은 엄격하게 검사를 받아야 하고, 임상 시험 데이터가 충분하지 않으면 승인이 거절되는 규정이 생겼죠. 특히, 잉란에서도 이런 법규가 시행되면서 의약 제품의 안정성이 크게 향상되었습니다. 이제는 모든 의료기관에서 정식으로 등록된 의약물을 판매하도록 되었고, 이를 위반하면 형사 처벌까지 받을 수 있게 되었습니다. 이처럼 탈라미 디 사건은 단순한 개인의 노력으로 시작되었다는 점에서 의미가 큽니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  파킨슨병을 알려줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 질문: '파킨슨병을 알려줘'\n",
      "DB cosine similarity = 0.6870\n",
      "\n",
      "[DAIS]\n",
      "파키슨병 관련 최신 연구 동향 및 진단 방법에 대한 정보를 제공하겠습니다. 현재 파킨병은 여전히 정확한 원인이나 치유 가능한 치매와 달리, 약물치료 중심으로 발전하고 있으며, 조기에 진단하면 더 좋은 예후를 보일 수 있다고 생각합니다. 하지만 대부분의 경우, 이미 일상생활에 지장이 생겼을 때 진단되곤 하는데, 이러한 문제를 개선하기 위해서는 더욱 효율적인 검사를 통해 조기에 발견하는 것이 중요하다고 강조드립니다. 특히, 머리카락 색깔 변화라는 간접적인 증징이 있다면, 이를 이용한 비침습적인 검사 방식이 가능하다는 사실도 소개하였습니다. 또한, 최근 연구에서는 특정 항체를 이용한 혈액검사를 통해 파킨센병을 조기에 감별할 수 있을 가능성도 있었습니다. — DAIS\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Metrics Summary ===\n",
      "cosine: min=0.4569, avg=0.6016, max=0.7671\n",
      "perplexity: min=8.5097, avg=32.6125, max=91.6779\n",
      "bleu4: min=0.0045, avg=0.3067, max=0.6844\n",
      "rougeL: min=0.0000, avg=0.0886, max=0.4000\n",
      "response_time: min=8.3797, avg=15.3021, max=24.9900\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 8. 채팅 루프 + 통계\n",
    "# ==============================================================================\n",
    "\n",
    "def chat_loop():\n",
    "    history = []\n",
    "    all_metrics = []\n",
    "    print(\"=== DAIS RAG Agent Chat (threshold=0.6) ===\\n(종료: exit)\")\n",
    "    while True:\n",
    "        q = input('>> ').strip()\n",
    "        if q.lower() == 'exit':\n",
    "            break\n",
    "        history.append(f'[USER] {q}')\n",
    "\n",
    "        # 직전 1턴 히스토리\n",
    "        hist = history[-2:] if len(history)>=2 and history[-2].startswith('[DAIS]') else history[-1:]\n",
    "        inputs = {'history': '\\n'.join(hist), 'input': q, 'output': ''}\n",
    "\n",
    "        # get output\n",
    "        db_out = tool_rag_db(q)\n",
    "        ctx = db_out['doc'].page_content if db_out['score']>=0.6 else tool_rag_wiki(q)['doc']\n",
    "        inputs['output'] = ctx\n",
    "        result = agent_chain.invoke(inputs)\n",
    "        if result.get('metrics'):\n",
    "            all_metrics.append(result['metrics'])\n",
    "        print(f\"\\n[DAIS]\\n{result['response']}\\n\")\n",
    "\n",
    "        # 메트릭 각각 출력\n",
    "        metrics = result['metrics']\n",
    "        print(f\"DB cosine similarity = {metrics['db_cosine']:.4f}\")\n",
    "        if metrics.get('wiki_cosine') is not None:\n",
    "            print(f\"Wikipedia cosine similarity = {metrics['wiki_cosine']:.4f}\")\n",
    "        print(f\"Perplexity = {metrics['perplexity']:.4f}\")\n",
    "        print(f\"BLEU-4 = {metrics['bleu4']:.4f}\")\n",
    "        print(f\"ROUGE-L = {metrics['rougeL']:.4f}\")\n",
    "        print(f\"Response time = {metrics['response_time']:.4f}s\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    # 종합 통계\n",
    "    print(\"=== Metrics Summary ===\")\n",
    "    \n",
    "    # 각 메트릭별로 None을 제거하고 배열 생성\n",
    "    for key in all_metrics[0].keys():\n",
    "        values = [m[key] for m in all_metrics if m[key] is not None]\n",
    "        if not values:\n",
    "            continue\n",
    "        arr = np.array(values)\n",
    "        print(f\"{key}: min={arr.min():.4f}, avg={arr.mean():.4f}, max={arr.max():.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "07d20abc-ac7a-46f9-a727-6c5d1a81bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 원소의 아버지 멘델레예프에 대해 설명좀 해줘\n",
    "# 2. 이차전지의 미래는 어떨거 같아?\n",
    "# 3. 아인슈타인에 대해 알고 싶어\n",
    "# 4. 정자 은행이 대체 뭔데?\n",
    "# 5. 퀴리 부인의 업적이 궁금해\n",
    "# 6. 뇌-컴퓨터 인터페이스(BCI) 기술을 간단히 알려줘\n",
    "# 7. 코로나 바이러스의 발생원인을 알려줘\n",
    "# 8. 리만 가설을 간단히 요약해봐\n",
    "# 9. 탈리도마이드 사건을 자세히 설명해봐\n",
    "# 10. 파킨슨병을 알려줘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80feea5-3260-4709-aaad-20a95e89227e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
